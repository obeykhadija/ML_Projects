# ML_Projects
## Machine learning projects

### Breast Cancer Classification
* Predict whether a cancer cell is benign or malignant.
* Cleaned and preprocessed data using Pandas, NumPy, and Scikit-learn.
* Evaluated two models Support Vector Machines (SVM) and Logistic Regression and used GridSearchCV to optimize models. 
* Demonstrated dimensionality reduction using principal component analysis (PCA)

### Loan Classification
* Predict whether a client’s loan is paid off or in collection
* Performed visual data analysis with matplotlib and seaborn, preprocessed data with feature extraction and data standardization using Pandas and Scikit-learn.
* Tested four supervised classifier models KNN, Decision Tree, SVM, and Logistic Regression.
* Evaluated each model using Scikit-learn to gather Jaccard score, f1 score, and log-loss. Recommended Logistic Regression with an accuracy of 76.9% on the test set.

### House Prediction
* The project aimed to create a model to make predictions for housing prices given various predictor variables.
* Clean data and preprocess (train-test split and data normalization) using Pandas and NumPy
* Perform exploratory data analysis to find patterns related to the sale price of a house. Visualized strong corollary relationships using seaborn, matplotlib, Jupyter notebook. 
* Demonstrated feature transformation using SciPy and Pandas
* Trained three separate Regressor models Linear, Ridge, and Lasso regression. Evaluated each model's R2 score and Mean Square Error (MSE). 
* Choose a Linear Regression Model with an R2 score of 0.853 and MSE of 0.0278. Optimize model with GridSearchCV.

### Alzheimer's Disease Classification
* Given various predictive variables of Alzheimer's (e.g., MMSE score, normalized whole brain volume), predict whether a patient has dementia or no dementia.
* Conducted standard approach to load and clean data using Pandas. 
* Performed exploratory data analysis to find patterns in Alzheimer’s data and aid in feature selection.
* Visualized strong corollary relationships using Seaborn, Matplotlib, and Jupyter notebook.
* Trained and evaluated four different classifier models Logistic Regression, KNN, Decision Tree, Neural Network, Random Forest, and Gradient Boosting using Scikit-learn.
* Assessed model performance by calculating accuracy and F1-Score. Visualized model 

### Drug Consumption
#### EDA
* Conducted a full EDA on a drug consumptions dataset. The data included personality scores, demographic information, and drug consumption frequency for over 15 drugs. 
* Conducted standard pipeline approach to load and clean data using Pandas.
* Encoded ordinal and nominal features for easy data manipulation.
* Described and visualized average use of each drug using matplotlib, seaborn, and Jupyter notebook.
* Provided comprehensive conclusions for each section of analysis including citations. 

#### Prediction
* Given several personality measures and demographic data can we predict whether someone will be a drug user or non-user.
* Collected and cleaned data from the UCI Machine Learning Repository 
* Conducted standard pipeline approach to load, clean, and preprocess data using Pandas, NumPy, and Scikit-learn.
* Demonstrated feature transformation and engineering with Pandas and NumPy
* Visualized corollary relationships with matplotlib, seaborn, and Jupyter notebook.
* Conducted predictive analysis on four drugs (cocaine, heroin, methamphetamines, and nicotine) using Logistic Regression, Ridge Classifier, Support Vector Machines, and Random Forest Classifier. 
* Assessed model performance by calculating accuracy and F1-Score. Predicted cocaine use with 100% accuracy, and nicotine use with 79.9 accuracies.

